# Test vector-cache-proxy from npm

This folder tests the published npm package `vector-cache-proxy`.

## Setup

```bash
npm install
```

## Requirements

- Node.js >= 18
- Redis server running on localhost:6379

## Run test

```bash
npm start
```

Or:

```bash
node index.js
```

## What it tests

1. âœ… Import from npm package
2. âœ… Initialize VectorCacheProxy
3. âœ… Get embedding from text
4. âœ… Set cache
5. âœ… Get cache with similar query (semantic search)
6. âœ… Cache miss with different query
7. âœ… Close connection

## Expected output

```
Testing vector-cache-proxy from npm...

Initializing model...
ğŸš€ Initializing model Xenova/all-MiniLM-L6-v2...
âœ… Model ready!

ğŸ“Œ Test 1: Getting embedding
âœ… Got embedding for "How to build a REST API?"
   Dimensions: 384
   First 5 values: [ ... ]

ğŸ“Œ Test 2: Setting cache
âœ… Cached response

ğŸ“Œ Test 3: Getting cache with similar query
âœ… Cache hit! Similarity: 95.23%
   Query: "How do I create a REST API?"
   Cached: "How to build a REST API?"
âœ… Cache hit!
   Response: { answer: '...', tokens: 150, model: 'gpt-4' }

ğŸ“Œ Test 4: Testing cache miss
âŒ Cache miss for query: "What is machine learning?"
âŒ Cache miss (expected)

ğŸ“Œ Cleanup
âœ… Connection closed

ğŸ‰ All tests completed successfully!
```
